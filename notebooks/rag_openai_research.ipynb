{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87ec5bae-47b3-408f-9923-32ad6d583344",
   "metadata": {},
   "source": [
    "# RAG Data Pipeline: OpenAI Research Page\n",
    "\n",
    "This notebook demonstrates how to use **Thordata's Universal Scraping API**\n",
    "to fetch a dynamic web page, clean the HTML into LLM-friendly text, and save\n",
    "it as a Markdown file ready for vector database ingestion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dc319dd-9e40-4f93-96df-0f0e4624aa93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from typing import List\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from thordata import ThordataClient\n",
    "\n",
    "load_dotenv()  # Load THORDATA_* tokens from .env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c414753-be59-419a-b936-16925fdca661",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_html_to_markdown(html_content: str) -> str:\n",
    "    \"\"\"\n",
    "    Convert messy HTML into Markdown-style text suitable for RAG / LLMs.\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "    # Remove irrelevant tags\n",
    "    for tag in soup([\"script\", \"style\", \"nav\", \"footer\", \"iframe\", \"noscript\"]):\n",
    "        tag.decompose()\n",
    "\n",
    "    markdown_lines: List[str] = []\n",
    "\n",
    "    # Headings (H1–H3)\n",
    "    for heading in soup.find_all([\"h1\", \"h2\", \"h3\"]):\n",
    "        level = int(heading.name[1])\n",
    "        prefix = \"#\" * level\n",
    "        markdown_lines.append(f\"\\n{prefix} {heading.get_text(strip=True)}\\n\")\n",
    "\n",
    "    # Paragraphs\n",
    "    for p in soup.find_all(\"p\"):\n",
    "        text = p.get_text(strip=True)\n",
    "        if len(text) > 20:\n",
    "            markdown_lines.append(text)\n",
    "\n",
    "    return \"\\n\".join(markdown_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "629e13d9-4b09-4a23-9da8-d7431fa42f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching page: https://openai.com/research/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "347665"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scraper_token = os.getenv(\"THORDATA_SCRAPER_TOKEN\")\n",
    "public_token = os.getenv(\"THORDATA_PUBLIC_TOKEN\")\n",
    "public_key = os.getenv(\"THORDATA_PUBLIC_KEY\")\n",
    "\n",
    "if not scraper_token:\n",
    "    raise ValueError(\"Please set THORDATA_SCRAPER_TOKEN in your .env file.\")\n",
    "\n",
    "client = ThordataClient(scraper_token, public_token, public_key)\n",
    "\n",
    "target_url = \"https://openai.com/research/\"\n",
    "\n",
    "print(f\"Fetching page: {target_url}\")\n",
    "html = client.universal_scrape(\n",
    "    url=target_url,\n",
    "    js_render=True,\n",
    "    output_format=\"HTML\",\n",
    ")\n",
    "len(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "018c7095-8fd6-4757-9a91-34fe62f35da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of cleaned markdown: 2719\n",
      "\n",
      "Preview:\n",
      "\n",
      "\n",
      "# Pioneering research on the path to AGI\n",
      "\n",
      "\n",
      "### We use Deep Learning to leverage large amounts of data and advanced reasoning to train AI systems for task completion.\n",
      "\n",
      "\n",
      "### GPT\n",
      "\n",
      "\n",
      "### o series\n",
      "\n",
      "\n",
      "### Visual\n",
      "\n",
      "\n",
      "### Audio\n",
      "\n",
      "\n",
      "### Text\n",
      "\n",
      "\n",
      "### Featured roles\n",
      "\n",
      "\n",
      "### Research Engineer\n",
      "\n",
      "\n",
      "### Research Engineer, Codex\n",
      "\n",
      "\n",
      "### Research Engineer, Frontier Evals & Environments\n",
      "\n",
      "\n",
      "### Research Scientist\n",
      "\n",
      "\n",
      "## Explore all research\n",
      "\n",
      "We believe our research will eventually lead to artificial general intelligence, a system that can solve human-level problems. Our mission is to ensure that AGI benefits all of humanity.\n",
      "OpenAI’s GPT series models are fast, versatile, and cost-efficient AI systems designed to understand context, generate content, and reason across text, images, and more.\n",
      "A smarter, more conversational ChatGPT\n",
      "ReleaseNov 12, 20258 min read\n",
      "Our smartest, fastest, and most useful model yet, with thinking built in\n",
      "ReleaseAug 7, 202515 min read\n",
      "Improved ability to recognize patterns and generate creative\n"
     ]
    }
   ],
   "source": [
    "markdown_content = clean_html_to_markdown(html)\n",
    "\n",
    "print(\"Length of cleaned markdown:\", len(markdown_content))\n",
    "print(\"\\nPreview:\\n\")\n",
    "print(markdown_content[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "896fd7eb-f4a4-4430-a962-537350a1cb75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to knowledge_base_sample.md\n"
     ]
    }
   ],
   "source": [
    "output_file = \"knowledge_base_sample.md\"\n",
    "\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(f\"Source: {target_url}\\n\\n\")\n",
    "    f.write(markdown_content)\n",
    "\n",
    "print(f\"Saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484665fe-c752-4fbd-938e-adc067675285",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
